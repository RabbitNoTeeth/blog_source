---
title: 神经网络的数学基础
description: 神经网络的数学基础
lang: zh-CN
---

## 1. 神经网络的数据表示：张量
一般来说，当前所有机器学习系统都使用张量作为基本数据结构。那么张量是什么？

**张量** 这一概念的核心在于，它是一个 **数据容器**。它包含的数据几乎总是数值数据，因此它是数字的容器。你可能对矩阵很熟悉，它是二维张量。**张量是矩阵向任意维度的推广**［注意，张量的 **维度（dimension）** 通常叫作 **轴（ axis）**］。

### 1.1 标量（0D 张量）
仅包含一个数字的张量叫作标量（scalar，也叫标量张量、零维张量、 0D 张量）。

在 Numpy 中，一个 float32 或 float64 的数字就是一个标量张量（或标量数组）。你可以用 ndim 属性来查看一个 Numpy 张量的轴的个数。标量张量有 0 个轴（ ndim == 0）。张量轴的个数也叫作 **阶（rank）**。

下面是一个 Numpy 标量。

```python
>>> import numpy as np
>>> x = np.array(12)
>>> x
array(12)
>>> x.ndim
0
```

### 1.2 向量（1D 张量）
数字组成的数组叫作向量（vector）或一维张量（ 1D 张量）。一维张量只有一个轴。下面是一个 Numpy 向量。

```python
>>> x = np.array([12, 3, 6, 14, 7])
>>> x
array([12, 3, 6, 14, 7])
>>> x.ndim
1
```

这个向量有 5 个元素，所以被称为 **5D 向量**。

不要把 5D 向量和 5D 张量弄混！ 5D 向量只有一个轴，沿着轴有 5 个维度，而 5D 张量有 5 个轴（沿着每个轴可能有任意个维度）。 

**维度（dimensionality）** 可以表示沿着某个轴上的元素个数（比如 5D 向量），也可以表示张量中轴的个数（比如 5D 张量），这有时会令人感到混乱。对于后一种情况，技术上更准确的说法是 **5 阶张量**（张量的阶数即轴的个数），但 **5D 张量** 这种模糊的写法更常见。


### 1.3 矩阵（2D 张量）
向量组成的数组叫作矩阵（matrix）或二维张量（2D 张量）。矩阵有 2 个轴（通常叫作行和列）。你可以将矩阵直观地理解为数字组成的矩形网格。下面是一个 Numpy 矩阵。

```python
>>> x = np.array([[5, 78, 2, 34, 0],
[6, 79, 3, 35, 1],
[7, 80, 4, 36, 2]])
>>> x.ndim
2
```

第一个轴上的元素叫作行（row），第二个轴上的元素叫作列（column）。在上面的例子中，[5, 78, 2, 34, 0] 是 x 的第一行， [5, 6, 7] 是第一列。


### 1.4 3D 张量与更高维张量
将多个矩阵组合成一个新的数组，可以得到一个 3D 张量，你可以将其直观地理解为数字组成的立方体。下面是一个 Numpy 的 3D 张量。

```python
>>> x = np.array([[[5, 78, 2, 34, 0],
[6, 79, 3, 35, 1],
[7, 80, 4, 36, 2]],
[[5, 78, 2, 34, 0],
[6, 79, 3, 35, 1],
[7, 80, 4, 36, 2]],
[[5, 78, 2, 34, 0],
[6, 79, 3, 35, 1],
[7, 80, 4, 36, 2]]])
>>> x.ndim
3
```

将多个 3D 张量组合成一个数组，可以创建一个 4D 张量，以此类推。深度学习处理的一般是 0D 到 4D 的张量，但处理视频数据时可能会遇到 5D 张量。

### 1.5 关键属性
张量是由以下三个关键属性来定义的。
- **轴的个数（阶）**

例如， 3D 张量有 3 个轴，矩阵有 2 个轴。这在 Numpy 等 Python 库中也叫张量的 ndim。

- **形状**

这是一个整数元组，表示张量沿每个轴的维度大小（元素个数）。例如，前面矩阵示例的形状为 (3, 5)， 3D 张量示例的形状为 (3, 3, 5)。向量的形状只包含一个元素，比如 (5,)，而标量的形状为空，即 ()。

- **数据类型**（在 Python 库中通常叫作 dtype）

这是张量中所包含数据的类型，例如，张量的类型可以是 float32、 uint8、 float64 等。在极少数情况下，你可能会遇到字符（char）张量。注意， Numpy（以及大多数其他库）中不存在字符串张量，因为张量存储在预先分配的连续内存段中，而字符串的长度是可变的，无法用这种方式存储。


### 1.6 在 Numpy 中操作张量
选择张量的特定元素叫作 **张量切片（tensor slicing）**。我们来看一下 Numpy 数组上的张量切片运算。

下面这个例子选择第 10~100 个数字（不包括第 100 个），并将其放在形状为 (90, 28,28) 的数组中。

```python
>>> my_slice = train_images[10:100]
>>> print(my_slice.shape)
(90, 28, 28)
```

<br>
它等同于下面这个更复杂的写法，给出了切片沿着每个张量轴的起始索引和结束索引。 注意， `:` 等同于选择整个轴。

```python
>>> my_slice = train_images[10:100, :, :]
>>> my_slice.shape
(90, 28, 28)
>>> my_slice = train_images[10:100, 0:28, 0:28]
>>> my_slice.shape
(90, 28, 28)
```

<br>
一般来说，你可以沿着每个张量轴在任意两个索引之间进行选择。例如，你可以在所有图像的右下角选出 14 × 14 像素的区域：

```python
my_slice = train_images[:, 14:, 14:]
```

<br>
也可以使用负数索引。与 Python 列表中的负数索引类似，它表示与当前轴终点的相对位置。 你可以在图像中心裁剪出 14 × 14 像素的区域：

```python
my_slice = train_images[:, 7:-7, 7:-7]
```


### 1.7 数据批量的概念
通常来说，深度学习中所有数据张量的第一个轴（0 轴，因为索引从 0 开始）都是 **样本轴**（samples axis，有时也叫 **样本维度**）。

此外，深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。

具体来看，下面是 MNIST 数据集的一个批量，批量大小为 128。

```python
batch = train_images[:128]
```

然后是下一个批量。

```python
batch = train_images[128:256]
```

然后是第 n 个批量。
```python
batch = train_images[128 * n:128 * (n + 1)]
```

对于这种批量张量，第一个轴（0 轴）叫作 **批量轴（batch axis）** 或 **批量维度（batch dimension）**。在使用 Keras 和其他深度学习库时，会经常遇到这个术语。

### 1.8 现实世界中的数据张量
我们用几个你未来会遇到的示例来具体介绍数据张量。你需要处理的数据几乎总是以下类别之一。 

- **向量数据**

2D 张量，形状为 (samples, features)。

- **时间序列数据**或**序列数据**

3D 张量，形状为 (samples, timesteps, features)。

- **图像**

4D 张量，形状为 (samples, height, width, channels) 或 (samples, channels, height, width)。

- **视频**

5D 张量，形状为 (samples, frames, height, width, channels) 或 (samples, frames, channels, height, width)。